//=================================================================================================
// Program		: 
// Class		: PS4.jj
// Developers	: Renae Fisher
// Abstract		:
//=================================================================================================

options {
	static = false;
}

PARSER_BEGIN(PS4Tokenizer)

import java.io.*;
import java.util.Random;
import java.util.HashMap;

public class PS4Tokenizer {

    static HashMap<String, Integer> matches;
    static String input;
    static String cleanOutput = "./clean-data/";

	public static void main(String[] args) throws ParseException, IOException {
        
        if(args.length == 1) {

            input = args[0];
            
            // Create directories.
            
            String[] dirNames = {cleanOutput};
            setupOutputDirs(dirNames);
 
            // Begin to tokenize each file.
            
            matches = new HashMap<String,Integer>();
            
            File indir = new File(input);
			File[] files = indir.listFiles();

            for(File file : files) {
				tokenize(file, cleanOutput);
            }

		} else {
			System.out.println("ERROR: Invalid arguments specified\n");
			System.out.println("Please run this program with the following syntax: java PS4Tokenizer.java <path of input dir>");
			System.exit(1);
		}
  	}

    private static void setupOutputDirs(String[] dirNames) {
 
        File dir;
        
        for(int i = 0; i < dirNames.length; i++) {
         
            dir = new File(dirNames[i]);
            
            if(!dir.exists()) {
                dir.mkdir();
            }
            
        }
        
    }
    
    private static BufferedWriter setupOutputFile(String fileName) throws IOException {
     
        File output = new File(fileName);
    
        if(output.exists())
            output.delete();
            
        output.createNewFile();
        
        return new BufferedWriter(new FileWriter(output));

    }

  	private static void tokenize(File input, String outPath) throws ParseException, IOException {
        
        String[] tmp;
        
        String fileName = input.getName();

		// Create training-data output
        
		BufferedWriter bw = setupOutputFile(outPath+fileName);
        
        // Open input file.
		BufferedReader br = new BufferedReader(new FileReader(input));
		PS4Tokenizer u = new PS4Tokenizer(br);
  		Token t;
        Token p = null;
        String key;
        boolean newline;

		do {

            t = u.getNextToken();
            
            newline = PS4Tokenizer.tokenImage[ t.kind ].equalsIgnoreCase("<NEWLINE>");

            if(!newline) {
             
                key = t.image;
                
                if(PS4Tokenizer.tokenImage[ t.kind ].equalsIgnoreCase("<WORD_SP2>")) {
                    key = key.substring(0,key.length()-1);
                    bw.write(key.toLowerCase());
                } else if(PS4Tokenizer.tokenImage[ t.kind ].equalsIgnoreCase("<WORD_SP0>")) {
                    
                    for(int i = 0; i < key.length(); i++) {
                    
                        if(Character.isUpperCase(key.charAt(i))) {
                            bw.write("\n");
                        }
                        
                        bw.write(key.charAt(i));

                    }
                    
                    bw.write(" ");

                } else {
                    bw.write(key.toLowerCase());
                }

            }

			if(newline) {

                // Write non-empty new lines.
                
                if( p != null ) {

                    if(Character.isLetter(p.image.charAt(0))) {
                        bw.write(t.image);
                    }

                }
                
            }
            
            p = t;
		
		} while ( t.kind != PS4TokenizerConstants.EOF );

  		br.close();
  		bw.close();

  	}
}

PARSER_END(PS4Tokenizer)

TOKEN_MGR_DECLS : {

}

SKIP : {

 < TAB : ("\t")+ >
| < CR : ("\r")+ >
| < OPERATOR : ["+","-","*","/"]|("&gt;") >
| < PUNCTUATION : (","|"?"|"!"|":"|"'"|"-"|"."|"&"|"/")+>
| < SPECIAL_ENTITY : ("&"(["a"-"z","A"-"Z"])+";"|"&#"(["0"-"9"])+";") >

}

// Skip tokens that are probably not relevant.

SKIP : {
  
  < EMAIL: (["a"-"z","A"-"Z","0"-"9"])+"@"((".")?["a"-"z","A"-"Z","0"-"9"])+ >
| < DOMAIN : "@"((".")?["a"-"z","A"-"Z"])+ >
| < PHONE_NUMBER :  (("(")?["0"-"9"]["0"-"9"]["0"-"9"](")")?(< SPACE >|"-"|".")+)+["0"-"9"]["0"-"9"]["0"-"9"]["0"-"9"] >
| < EQUATION : ((["0"-"9"])+(< SPACE >)?(< OPERATOR >)?(< SPACE >)?)+(< SPACE >)?("="(< SPACE >)?(["0"-"9"](".")?)+)? >
| < NUMBER      : ((".")?(["0"-"9"])+(",")?)+ >

}

// We're specifically looking for words.

TOKEN : {

  
  < WORD_SP0 : <SPACE>(["a"-"z","A"-"Z"])+(["A"-"Z"]|"."){1}(["a"-"z","A"-"Z"])+<SPACE> >  
| < WORD_SP1 : (["a"-"z","A"-"Z"])+"'"(["a"-"z","A"-"Z"])+ >
| < WORD_SP2 : (["a"-"z","A"-"Z"]){1}(["a","e","i","o","u"]){1}(["a"-"z","A"-"Z"]){1}(["a","e","i","o","u"]){1}("s") >
| < WORD  : (["a"-"z","A"-"Z"])+ >
| < SPACE : (" "|"\\s")+ >
| < NEWLINE : ("\n"|("?"|"!"|"."))+ >
| < MISC  : ~[] >

}
